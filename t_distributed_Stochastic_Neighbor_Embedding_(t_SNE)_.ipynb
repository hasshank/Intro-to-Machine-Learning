{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.nn.functional as F\n",
        "from sklearn.manifold import TSNE\n",
        "import matplot\n",
        "from matplotlib import pyplot as plt\n",
        "import tqdm.notebook as tqdm"
      ],
      "metadata": {
        "id": "tDQcj95buMJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "I2Oz0WF1qSSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/gdrive/MyDrive/cifar10_classifier_large.pth"
      ],
      "metadata": {
        "id": "YSXxNwjjqZFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device\", device)\n",
        "\n",
        "transform = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.ToTensor(),\n",
        "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "training_data = torchvision.datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform)\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform)\n",
        "\n",
        "batch_size = 4\n",
        "trainloader = torch.utils.data.DataLoader(training_data, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "kQAFpXvhuP6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = [training_data[i][0] for i in range(9)]\n",
        "plt.imshow(torchvision.utils.make_grid(torch.stack(images), nrow=3, padding=5).numpy().transpose((1,2,0)))"
      ],
      "metadata": {
        "id": "D3x07UnIrO1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ..."
      ],
      "metadata": {
        "id": "DaIx-yGWroe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 128, 3, 1, 1)\n",
        "    self.bn1 = nn.BatchNorm2d(128)\n",
        "    self.conv2 = nn.Conv2d(128, 128, 3, 1, 1)\n",
        "    self.bn2 = nn.BatchNorm2d(128)\n",
        "    self.pool1 = nn.MaxPool2d(2)\n",
        "    self.conv3 = nn.Conv2d(128, 256, 3, 1, 1)\n",
        "    self.bn3 = nn.BatchNorm2d(256)\n",
        "    self.conv4 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "    self.bn4 = nn.BatchNorm2d(256)\n",
        "    self.pool2 = nn.MaxPool2d(2)\n",
        "    self.linear1 = nn.Linear(256 * 8 * 8, 256)\n",
        "    self.bn_l1 = nn.BatchNorm1d(256)\n",
        "    self.linear2 = nn.Linear(256, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.bn1(F.relu(self.conv1(x)))\n",
        "    out = self.bn2(F.relu(self.conv2(out)))\n",
        "    out = self.pool1(out)\n",
        "    out = self.bn3(F.relu(self.conv3(out)))\n",
        "    out = self.bn4(F.relu(self.conv4(out)))\n",
        "    out = self.pool2(out)\n",
        "    out = torch.flatten(out, start_dim=1)\n",
        "    out = self.bn_l1(F.relu(self.linear1(out)))\n",
        "    out = self.linear2(out)\n",
        "    return out\n",
        "\n",
        "net = Net().to(device)\n",
        "model_save_name = 'cifar10_classifier_large.pth'\n",
        "path = F\"/content/gdrive/MyDrive/{model_save_name}\"\n",
        "net.load_state_dict(torch.load(path))\n",
        "net.eval()"
      ],
      "metadata": {
        "id": "UnOZtq6Hrpq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ..."
      ],
      "metadata": {
        "id": "OgC1EL1ntleJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveFeatures():\n",
        "  features = None\n",
        "  def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
        "  def hook_fn(self, module, input, output): self.features = ((output.cpu()).data).numpy()\n",
        "  def remove(self): self.hook.remove()"
      ],
      "metadata": {
        "id": "sdrW7fBlt5xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features_from_layer(layer):\n",
        "  activated_features = SaveFeatures(layer)\n",
        "  return activated_features"
      ],
      "metadata": {
        "id": "c_MBCWkNtmRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ..."
      ],
      "metadata": {
        "id": "3EvgChUMuF2m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}