{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJidYgbr7B26"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "print(\"Pytorch has version {}\".format(torch.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch_version = str(torch.__version__)\n",
        "scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "!pip install torch-scatter -f $scatter_src\n",
        "!pip install torch-sparse -f $sparse_src\n",
        "!pip install torch-geometric\n",
        "!pip install ogb"
      ],
      "metadata": {
        "id": "phfZ4rN07cIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "\n",
        "root = './enzymes'\n",
        "name = 'ENZYMES'\n",
        "\n",
        "pyg_dataset = TUDataset(root, name)\n",
        "\n",
        "print(pyg_dataset)"
      ],
      "metadata": {
        "id": "f7HmKToc8At8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_classes(pyg_dataset):\n",
        "\n",
        "  # ...\n",
        "\n",
        "  num_classes =\n",
        "\n",
        "  return num_classes\n",
        "\n",
        "def get_num_features(pyg_dataset):\n",
        "\n",
        "  # ...\n",
        "\n",
        "  num_features =\n",
        "\n",
        "  return num_features\n",
        "\n",
        "num_classes = get_num_classes(pyg_dataset)\n",
        "num_features = get_num_features(pyg_dataset)\n",
        "print(\"{} dataset has {} classes\".format(name, num_classes))\n",
        "print(\"{} dataset has {} features\".format(name, num_features))"
      ],
      "metadata": {
        "id": "KG63YGqi8ewq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_graph_class(pyg_dataset, idx):\n",
        "\n",
        "  #...\n",
        "\n",
        "  label =\n",
        "\n",
        "  return label\n",
        "\n",
        "graph_0 = pyg_dataset[0]\n",
        "print(graph_0)\n",
        "idx = 100\n",
        "label = get_graph_class(pyg_dataset, idx)\n",
        "print('Graph with index {} has label {}'.format(idx, label))"
      ],
      "metadata": {
        "id": "Rhz6TKn5SgX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index = graph_0.edge_index\n",
        "print(edge_index.t())"
      ],
      "metadata": {
        "id": "BuNpxmopTgox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_graph_num_edges(pyg_dataset, idx):\n",
        "\n",
        "  # ...\n",
        "\n",
        "  num_edges =\n",
        "\n",
        "  return num_edges\n",
        "\n",
        "idx = 200\n",
        "num_edges = get_graph_num_edges(pyg_dataset, idx)\n",
        "print('Graph with index {} has {} edges'. format(idx, num_edges))"
      ],
      "metadata": {
        "id": "MNDtsVQ9Tp4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric.transforms as T\n",
        "from ogb.nodeproppred import PygNodePropPredDataset\n",
        "\n",
        "dataset_name = 'ogbn-arxiv'\n",
        "\n",
        "dataset = PygNodePropPredDataset(name=dataset_name,\n",
        "                                 transform=T.ToSparseTensor())\n",
        "print('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\n",
        "\n",
        "data = dataset[0]\n",
        "rox, col, edge_attr = data.adj_t.t().coo()\n",
        "data.edge_index = torch.stack([row, col], dim=0)\n",
        "print(data)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print('Device : {}'.format(device))\n",
        "data = data.to(device)\n",
        "\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_idx = split_idx['train'].to(device)"
      ],
      "metadata": {
        "id": "UfDi8FaGUHUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "iport torch.nn.functional as F\n",
        "print(torch.__version__)\n",
        "\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "\n",
        "import pandas as pd\n",
        "import copy"
      ],
      "metadata": {
        "id": "pfrPjh46Wyq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    # ...\n",
        "\n",
        "    self .convs =\n",
        "\n",
        "    self.bns =\n",
        "\n",
        "    self.dropout = dropout\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    for conv in self.convs:\n",
        "      conv.reset_parameters()\n",
        "    for bn in self.bns:\n",
        "      bn.reset_parameters()\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "\n",
        "    # ...\n",
        "\n",
        "    out =\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "x29jo62hXIX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data, train_idx, optimizer, loss_fn):\n",
        "  model.train()\n",
        "  loss = 0\n",
        "\n",
        "  # ...\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return loss.item()"
      ],
      "metadata": {
        "id": "4LtQ4aNdX-Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test(model, data, split_idx, evaluator):\n",
        "\n",
        "  # ...\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  out = model(data.X, data.edge_index)\n",
        "\n",
        "  y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "  train_acc = evaluator.eval({\n",
        "      'y_true': data.y[split_idx['train']],\n",
        "      'y_pred': y_pred[split_idx['train']],\n",
        "      })['acc']\n",
        "      valid_acc = evaluator.eval({\n",
        "          'y_true': data.y[split_idx['valid']],\n",
        "      })['acc']\n",
        "\n",
        "      return train_acc, valid_acc"
      ],
      "metadata": {
        "id": "XgkjbkmqYMeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    'device': device,\n",
        "    'num_layers': 3,\n",
        "    'hidden_dim': 256,\n",
        "    'dropout': 0.5,\n",
        "    'lr': 0.01,\n",
        "    'epochs': 100,\n",
        "}"
      ],
      "metadata": {
        "id": "agGIrYpfZQGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GNN(data.num_features, args['hidden_dim'],\n",
        "            dataset.num_classes, args['num_layers'],\n",
        "            args['dropout']).to(device)\n",
        "evaluator = Evaluator(name='ogbn-arxiv')"
      ],
      "metadata": {
        "id": "bB2NhKQegEHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.reset_parameters()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "loss_fn = F.cross_entropy\n",
        "\n",
        "best_model = None\n",
        "best_valid_acc = 0\n",
        "\n",
        "print('Evaluating a randomly initialized model')\n",
        "result = test(model, data, split_idx, evaluator)\n",
        "train_acc, valid_acc = result\n",
        "print(f'Train: {100 * train_acc:.2f}%, '\n",
        "      f'Valid: {100 * valid_acc:.2f}%')\n",
        "\n",
        "for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "  loss = train(model, data, train_idx, optimizer, loss_fn)\n",
        "  result = test(model, data, split_idx, evaluator)\n",
        "  train_acc, valid_acc = result\n",
        "  if valid_acc > best_valid_acc:\n",
        "    best_valid_acc = valid_acc\n",
        "    best_model = copy.deepcopy(model)\n",
        "  print(f'Epoch: {epoch:02d}, '\n",
        "        f'Loss: {loss:.4f}, '\n",
        "        f'Train: {100 * train_acc:.2f}%, '\n",
        "        f'Valid: {100 * valid_acc:.2f}%')"
      ],
      "metadata": {
        "id": "mtYYf0-9g1fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_result = test(best_model, data, split_idx, evaluator)\n",
        "train_acc, valid_acc = best_result\n",
        "\n",
        "print(f'Best model: '\n",
        "      f'Train: {100 * train_acc:.2f}%, '\n",
        "      f'Valid: {100 * valid_acc:.2f}%')\n",
        "\n",
        "best_model.eval()\n",
        "out = best_model(data.x, data.edge_index)\n",
        "y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "print(\"Saving Model Predictions\")\n",
        "\n",
        "preds = {}\n",
        "preds['y_pred'] = y_pred[split_idx['test']].view(-1).cpu().detach().numpy()\n",
        "\n",
        "df = pd.DataFrame(data=preds)\n",
        "df.to_csv('ogbn-arxiv_node.csv', sep=',', index=False)"
      ],
      "metadata": {
        "id": "hg4lM30hPeZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
        "from torch_geometric.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device: {}'.format(device))\n",
        "\n",
        "split_idx = dataset.get_idx_split()\n",
        "\n",
        "print('Task type: {}'.format(dataset.task_type))"
      ],
      "metadata": {
        "id": "VniU5btdUCHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True, num_workers=0)\n",
        "valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "2xpMI0M7U3XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "class GNN_Graph(torch.nn.Module):\n",
        "  def __init__(self, hidden_dim, output_dim, num_layers, dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    self.node_encoder = AtomEncoder(hidden_dim)\n",
        "\n",
        "    self.gnn_node = GNN(hidden_dim, hidden_dim, hiddem_dim, num_layers, dropout)\n",
        "\n",
        "    # ...\n",
        "\n",
        "    self.pool =\n",
        "\n",
        "    self.linear = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    self.gnn_node.reset_parameters()\n",
        "    self.linear.reset_parameters()\n",
        "\n",
        "  def forward(self, batched_data):\n",
        "\n",
        "    # ...\n",
        "\n",
        "    x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n",
        "    embed = self.node_encoder(x)\n",
        "\n",
        "    # ...\n",
        "\n",
        "    out =\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "1LkWJOGIVZvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, data_loader, optimizer, loss_fn):\n",
        "  model.train()\n",
        "  loss = 0\n",
        "\n",
        "  for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")):\n",
        "    batch = batch.to(device)\n",
        "\n",
        "    if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n",
        "      pass\n",
        "    else:\n",
        "      is_labeled = batch.y == batch.y\n",
        "\n",
        "      # ...\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  return loss.item()"
      ],
      "metadata": {
        "id": "-VZd3TWiWy_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, device, loader, evaluator):\n",
        "  model.eval()\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
        "    batch = batch.to(device)\n",
        "\n",
        "    if batch.x.shape[0] == 1:\n",
        "      pass\n",
        "    else:\n",
        "      with torch.no_grad():\n",
        "        pred = model(batch)\n",
        "\n",
        "      y_true.apped(batch.y.view(pred.shape).detach().cpu())\n",
        "      y_pred.append(pred.detach().cpu())\n",
        "\n",
        "  y_true = torch.cat(y_true, dim = 0).numpy()\n",
        "  y_pred = torch.cat(y_pred, dim = 0).numpy()\n",
        "\n",
        "  input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
        "\n",
        "  return evaluator.eval(input_dict)"
      ],
      "metadata": {
        "id": "qnvbjnpFXm0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    'device': device,\n",
        "    'num_layers': 6,\n",
        "    'hidden_dim': 256,\n",
        "    'dropout': 0.2,\n",
        "    'lr': 0.0001,\n",
        "    'epochs': 30,\n",
        "}"
      ],
      "metadata": {
        "id": "YdjX3r-lb3zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GNN_Graph(args['hidden_dim'],\n",
        "                  dataset.num_tasks, args['num_layers'],\n",
        "                  args['dropout']).to(device)\n",
        "evaluator = Evaluator(name='ogbg-molhiv')"
      ],
      "metadata": {
        "id": "HioSHBEndXq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.reset_parameters()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "loss_fn = F.cross_entropy\n",
        "\n",
        "best_model = None\n",
        "best_valid_acc = 0\n",
        "\n",
        "print('Evaluating a randomly initialized model')\n",
        "train_result = eval(model, device, train_loader, evaluator)\n",
        "val_result = eval(model, device, valid_loader, evaluator)\n",
        "print(f'Train: {100 * train_acc:.2f}%, '\n",
        "      f'Valid: {100 * valid_acc:.2f}%')\n",
        "\n",
        "for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "  print('Training...')\n",
        "  loss = train(model, device, train_loader, optimizer, loss_fn)\n",
        "\n",
        "  print('Evaluating...')\n",
        "  train_result = eval(model, device, train_loader, evaluator)\n",
        "  val_result = eval(model, device, valid_loader, evaluator)\n",
        "\n",
        "  train_acc, valid_acc = train_result[dataset.eval_metric], val_result[dataset.eval_metric]\n",
        "  if valid_acc > best_valid_acc:\n",
        "    best_valid_acc = valid_acc\n",
        "    best_model = copy.deepcopy(model)\n",
        "  print(f'Epoch: {epoch:0.2d}, '\n",
        "        f'Loss: {loss:.4f}, '\n",
        "        f'Train: {100 * train_acc:.2f}%, '\n",
        "        f'Valid: {100 * valid_acc:.2f}%')"
      ],
      "metadata": {
        "id": "8qMgzR06dvFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_auroc = eval(best_model, device, train_loader, evaluator)[dataset.eval_metric]\n",
        "valid_auroc = eval(best_model, device, valid_loader, evaluator)[dataset.eval_metric]\n",
        "\n",
        "print(f'Best model: '\n",
        "      f'Train: {100 * train_auroc:.2f}%, '\n",
        "      f'Valid: {100 * valid_auroc:.2f}%')\n",
        "\n",
        "test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=False, num_workers=0)\n",
        "best_model.eval()\n",
        "with torch.no_grad():\n",
        "  y_pred = []\n",
        "  for step, batch in enumerate(tqdm(test_loader, desc=\"Iteration\")):\n",
        "    batch = batch.to(device)\n",
        "\n",
        "    if batch.x.shape[0] == 1:\n",
        "      pass\n",
        "    else:\n",
        "      pred = model(batch)\n",
        "      y_pred.append(pred.detach().cpu())\n",
        "\n",
        "y_pred = torch.cat(y_pred, dim=0).numpy()\n",
        "\n",
        "print(\"Saving Model Predictions\")\n",
        "\n",
        "pred = {}\n",
        "preds['y_pred'] = y_pred.reshape(-1)\n",
        "\n",
        "df = pd.DataFrame(data=preds)\n",
        "\n",
        "df.to_csv('ogbg-molhiv_graph.csv', sep=',', index=False)"
      ],
      "metadata": {
        "id": "CM-Yl7PDR_Wj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}